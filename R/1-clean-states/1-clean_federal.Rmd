---
  title: "Clean Federal data - COVID-19 Behind Bars Historical Data Cleaning"
author: "Hope Johnson"
date: "8/24/21"
output: html_document
---
  
```{r package setup, include=FALSE}
##Define package list
Packages<-c("tidyverse", "glue", "assertthat", "stringr", "lubridate", "devtools", "rlang")
.packages = Packages
##Install CRAN packages (if not already installed)
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) install.packages(.packages[!.inst])
##Load packages into session 
lapply(.packages, require, character.only=TRUE)
devtools::install_github("uclalawcovid19behindbars/behindbarstools")
```

## Intro & Credits

This script is used to clean one state in the historical data concerning COVID-19 in state and federal prisons. Contributors to the historical data cleaning efforts include Hope Johnson, Michael Everett, Neal Marquez, Chase Hommeyer, Grace DiLaura, and Kalind Parish. Contributors to larger project include Sharon Dolovich, Aaron Littman, Danielle Flores, Poornima Rajeshwar, Victoria Rossi, and many others. 


## Load inputs

Input files: 
  
* Utilities script
* Historical data
* Date range to clean 
* Facility name look-up table 

```{r load inputs, echo=FALSE}
base_path <- file.path("~", "UCLA", "code", "historical-data")
data_path <- file.path(base_path, "data", "inputs")
util_path <- file.path(base_path, "R", "0-utilities.R")
source(util_path, local = knitr::knit_global())
```

## Extract Data

```{r}
## offset starts at 0 and progresses by 2,000
## resident cases URL 
grab_bop_data <- function(call_type, offset_limit) {
  df_total = data.frame()
  url_base <- glue("https://services5.arcgis.com/6zMLz8j1ZaiDC1Ud/arcgis/rest/services/{call_type}_Public/FeatureServer/0/query?f=json&cacheHint=true&")
  url_ending <- "&resultRecordCount=2000&where=1%3D1&orderByFields=&outFields=*&returnGeometry=false&spatialRel=esriSpatialRelIntersects"
  offset = 0 
  while (offset <= offset_limit) {
    offset_val <- glue("resultOffset={offset}")
    full_url <- glue('{url_base}{offset_val}{url_ending}')
    json_data <- full_url %>% jsonlite::read_json(simplifyVector = TRUE)
    out_data <- as_tibble(json_data$features$attributes) %>%
      mutate(Date_transmuted = as.Date(as.POSIXct(as.numeric(Date) / 1000,
                                                  origin = "1970-01-01",
                                                  tz = "GMT")))
      df_total <- rbind(df_total, out_data)
      offset <- offset + 2000
  }
  return(df_total)
}

res_cases_raw <- grab_bop_data("COVID_FAC_COUNTY_INMATE", 66000)
staff_cases_raw <- grab_bop_data("COVID_FAC_COUNTY_STAFF", 66000) 
res_testing_raw <- grab_bop_data("COVID_BOP_Testing_Fac", 58000) 

## group facilities to the level of aggregation we xwalk to 
staff_cases_coalesced <- staff_cases_raw %>% 
  behindbarstools::group_by_coalesce(., BOP_Naming_Convention, Date_transmuted, method = "sum")
res_cases_coalesced <- res_cases_raw %>% 
  behindbarstools::group_by_coalesce(., BOP_Naming_Convention, Date_transmuted, method = "sum")
res_testing_coalesced <- res_testing_raw %>% 
  behindbarstools::group_by_coalesce(., BOP_Naming_Convention, Date_transmuted, method = "sum")

## clean and combine dfs
out_data <- list(staff_cases_coalesced, res_cases_coalesced, res_testing_coalesced) %>% 
  reduce(full_join, by = c("Date_transmuted", "BOP_Naming_Convention")) %>%
  select(Date = Date_transmuted,
       Name = BOP_Naming_Convention,
       Residents.Active = Inmates_Active,
       Residents.Deaths = Inmate_Deaths,
       Residents.Recovered = Inmates_Recovered,
       Staff.Active = Staff_Active,
       Staff.Deaths = Staff_Deaths,
       Staff.Recovered = Staff_Recovered,
       Residents.Tested = Inmates_Completed_Tests,
       Residents.Confirmed = Inmates_Positive_Tests
       ) 
nrow(out_data)
skim(out_data)

## only want 1 clean name/date combo per row
assert_that(nrow(out_data) == nrow(distinct(out_data, Name, Date)))

```

## Clean data

```{r}
## NB: not sure if "Other - RRC" should map to "ALL BOP RESIDENTIAL REENTRY CENTERS" 

df_mid <- out_data %>%
  mutate(Jurisdiction = "federal",
         State = NA_character_) %>% 
  behindbarstools::clean_facility_name(., debug = TRUE) %>%
  behindbarstools::group_by_coalesce(., Name, Date, method = "sum") %>% ## another group_by_coalesce for "ALL BOP RESIDENTIAL REENTRY CENTERS"
  filter(Date < as.Date("2020-10-26")) %>%
  mutate(state_full = State,  
    State = unname(toupper(behindbarstools::translate_state(state_full, reverse = TRUE))),
    State = ifelse(state_full == "Not Available", "Not Available", State),
    State = ifelse(state_full == "Puerto Rico", "PR", State),
    ) %>%
  filter(Name != "OTHER - CI") ## very little data and no clear facility 

df_mid %>%
  filter(name_match == FALSE) %>% 
  select(scrape_name_clean) %>%
  unique()

## only want 1 clean name/date combo per row
assert_that(nrow(df_mid) == nrow(distinct(df_mid, Name, Date)))

df_mid %>% 
    group_by(Name, Date) %>% 
    summarise(n_fac_date = n(),
              fac = first(Name),
              date = first(Date)) %>% 
  ungroup() %>%
  filter(n_fac_date > 1)
```

## Write data

```{r}
state_abbrev <- 'federal'
df_hist_towrite <- prep_server_data(df_mid, state_abbrev)
srvr_outfile_name <- glue('1-pre-november-{state_abbrev}.csv')
write_csv(df_hist_towrite, file.path(base_path, "data", "pre-nov", srvr_outfile_name))
sync_remote_files(srvr_outfile_name)
```








